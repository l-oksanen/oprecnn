{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inversion of 2 by 2 matrices using an operator recurrent neural network\n",
    "\n",
    "We use a simplified version of the network architecture proposed in the preprint\n",
    "\n",
    "> Maarten V. de Hoop, Matti Lassas, Christopher A. Wong. _Deep learning architectures for nonlinear operator functions and nonlinear inverse problems_. [arXiv:1912.11090](https://arxiv.org/abs/1912.11090)\n",
    "\n",
    "and teach it to invert matrices $X$ of the form $X = R D R^T$ where\n",
    "\n",
    "$$\n",
    "R = \\begin{pmatrix}\n",
    "c & -s\n",
    "\\\\\n",
    "s & c\n",
    "\\end{pmatrix},\n",
    "\\quad\n",
    "D = \\begin{pmatrix}\n",
    "\\lambda_1 & 0\n",
    "\\\\\n",
    "0 & \\lambda_2\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "$c = \\cos(\\alpha)$ and $s = \\sin(\\alpha)$ for some $\\alpha \\in (0,2\\pi)$,\n",
    "and $\\lambda_j \\in (1/2, 3/2)$, $j=1,2$.\n",
    "\n",
    "We use notations as in version 3 of the preprint (revised 3 Jan 2022). The notation is different in earlier version.\n",
    "\n",
    "In the code, variables have the same meaning as in the [Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) guige of PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "The operator recurrent architecture is implemented in `opnet` module, and \n",
    "generation of learning data in `simple_inversion_data`. \n",
    "\n",
    "File `PATH` is used to save the parameters of the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os #help navigate files in folder\n",
    "import matplotlib.pyplot as plt #plotting\n",
    "import pandas as pd #data frames = nice table\n",
    "\n",
    "import opnet\n",
    "from simple_inversion_data import generate_data, save_data, load_data\n",
    "\n",
    "PATH = './simple_inversion_netTEST.pth' #network that can be overwritten\n",
    "#PATH = './simple_inversion_net4.pth'\n",
    "# PATH = './simple_inversion_netPlusMinusReLU.pth'\n",
    "# PATH = './simple_inversion_netNEGA.pth'\n",
    "# PATH = './simple_inversion_netReLU.pth'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the network model and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dim = 2 # use 2 x 2 matrices\n",
    "num_layers = 5\n",
    "# luodaan uusi neuroverkko\n",
    "model = opnet.OperatorNet(dim, 2*num_layers, useReLU=False)\n",
    "#model = opnet.OperatorNet(dim, num_layers, useReLU=True) \n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of training data\n",
    "\n",
    "Training data consists of pairs $(X,y)$ where $X$ is an invertible $2 \\times 2$ matrix and $y = X^{-1} v$\n",
    "where $v = (1,1) \\in \\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_data(*generate_data(60000), \"simple_inversion_train_dataPOSNEG.npz\")\n",
    "#save_data(*generate_data(10000), \"simple_inversion_test_dataPOSNEG.npz\")\n",
    "\n",
    "train_data_path = \"simple_inversion_train_dataPOSNEG.npz\"\n",
    "test_data_path = \"simple_inversion_test_dataPOSNEG.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import training_and_testing\n",
    "import os.path\n",
    "\n",
    "# update changes\n",
    "from importlib import reload \n",
    "reload(training_and_testing)\n",
    "reload(opnet)\n",
    "\n",
    "# Liva:\n",
    "#lr_list = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "lr_list = [1e-1]\n",
    "losses_list=[]\n",
    "# same as below\n",
    "# upload the neural network used earlier:\n",
    "# if os.path.exists(PATH):\n",
    "#     model.load_state_dict(torch.load(PATH))\n",
    "# else:\n",
    "#     print(\"No old path, creating new one\")\n",
    "#     torch.save(model.state_dict(), PATH)\n",
    "#     model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "#calculates the average loss to the learning rate(s) above and a new row of avr loss into table\n",
    "for lr in lr_list:\n",
    "    losses_list.append(training_and_testing.training_and_testing(model, loss_fn,lr, PATH, train_data_path, test_data_path))\n",
    "#Liva\n",
    "\n",
    "\n",
    "# lr=1e-1\n",
    "# # upload the neural network used earlier:\n",
    "# if os.path.exists(PATH):\n",
    "#     #print(\"vittu jeejee\")\n",
    "#     model.load_state_dict(torch.load(PATH)) \n",
    "# else:\n",
    "#     print(\"no old PATH, I'll make a new one\")\n",
    "\n",
    "# training_and_testing.training_and_testing(model, loss_fn, lr)\n",
    "\n",
    "# #chech if network uses relu\n",
    "# doesit = model.does_it_use_relu()\n",
    "# #layer = model.layers[0].A\n",
    "# #print(\"testi layer on \", layer)\n",
    "\n",
    "# Load the training data\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     load_data(\"simple_inversion_train_data.npz\"), \n",
    "#     batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "#Liva\n",
    "# x-coordinates: HOW MANY YOU HAVE?!\n",
    "# now from 2 to 20 and every other\n",
    "epo = np.arange(0,40,2)+2\n",
    "print(epo)\n",
    "\n",
    "# plot the figure\n",
    "from matplotlib.lines import lineStyles\n",
    "plt.plot(epo, losses_list[0], label = 'lr=1e-1', linestyle='--')\n",
    "# plt.plot(epo, losses_list[1], label = 'lr=1e-3', linestyle='--')\n",
    "# plt.plot(epo, losses_list[2], label = 'lr=1e-2', linestyle='--')\n",
    "# plt.plot(epo, losses_list[3], label = 'lr=1e-1', linestyle='--')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the optimization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate parameter is from the quickstart guide \n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the training data multiple times (epochs) and \n",
    "save the optimized parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(2): \n",
    "#     print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "#     for batch, (X, y) in enumerate(train_loader):\n",
    "#         # Compute prediction error\n",
    "#         pred = model(X)\n",
    "#         loss = loss_fn(pred, y)\n",
    "#         # Backpropagation\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         # Print statistics\n",
    "#         if batch % 100 == 0:\n",
    "#             n, N = (batch + 1) * len(X), len(train_loader.dataset)\n",
    "#             print(f\"loss: {loss.item():>7f}  [{n:>5d}/{N:>5d}]\")\n",
    "\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "If we have already trained the network, we can just load its parameters. (Note that we still need to run the initialization.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load trained variables\n",
    "# model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the testing data\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     load_data(\"simple_inversion_test_data.npz\"), \n",
    "#     batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a couple of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(test_loader)\n",
    "# X, y = dataiter.next()\n",
    "# with torch.no_grad():\n",
    "#     pred = model(X)\n",
    "# print(\"True: \")\n",
    "# print(y[:2])\n",
    "# print(\"Prediction: \")\n",
    "# print(pred[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_batches = len(test_loader)\n",
    "# test_loss = 0\n",
    "# with torch.no_grad():\n",
    "#     for X, y in test_loader:\n",
    "#         pred = model(X)\n",
    "#         test_loss += loss_fn(pred, y).item()\n",
    "# test_loss /= num_batches\n",
    "# print(f\"Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('oprecnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c224d568f0f8fe9cd67a2fae7eb3734fc94b3a5cce8cb776805a0b269447ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
