{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse problem for the wave equation using an operator recurrent neural network\n",
    "\n",
    "We consider the inverse problem to find $a$ in the below wave equation given \n",
    "the Neumann-to-Dirichlet map \n",
    "\n",
    "$$\n",
    "\\Lambda h = u|_{x = 0},\n",
    "$$\n",
    "\n",
    "where $u$ is the solution to the problem \n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\partial_t^2 u - a(x) \\partial_x^2 u = 0, & \\text{on $(0,T) \\times (0,L)$},\n",
    "\\\\\n",
    "\\partial_x u|_{x=0} = h, \\quad \\partial_x u|_{x=L} = 0,\n",
    "\\\\\n",
    "u|_{t=0} = 0, \\quad \\partial_t u|_{t=0} = 0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Here we consider only a subproblem related to the inverse problem to find $a$.\n",
    "In Section 2 of \n",
    "\n",
    "> Jussi Korpela, Matti Lassas and Lauri Oksanen.\n",
    "> _Regularization strategy for an inverse problem for a 1 + 1 dimensional wave equation_.\n",
    "> Inverse Problems 32, 065001, 2016.\n",
    "> <https://doi.org/10.1088/0266-5611/32/6/065001> \n",
    "\n",
    "it was shown that $\\Lambda$ determines the following volumes \n",
    "\n",
    "$$\n",
    "V(r) = \\int_0^{\\chi(r)} \\frac{1}{c(x)^2} dx\n",
    "$$\n",
    "\n",
    "and that these volumes then determine $a$.\n",
    "Here $c^2 = a$ and $\\chi$ is the inverse function of $\\tau$ defined by\n",
    "\n",
    "$$\n",
    "\\tau(y) = \\int_0^y \\frac{1}{c(x)} dx.\n",
    "$$\n",
    "\n",
    "\n",
    "We consider the subproblem to compute a single volume $V(r_0)$, with fixed $r_0>0$, given $\\Lambda$. \n",
    "We solve this problem using a neural network, with the network architecture taken from \n",
    "\n",
    "> Maarten V. de Hoop, Matti Lassas, Christopher A. Wong. _Deep learning architectures for nonlinear operator functions and nonlinear inverse problems_. [arXiv:1912.11090](https://arxiv.org/abs/1912.11090)\n",
    "\n",
    "The training data consists of pairs $(\\Lambda, V(r_0))$ corresponding to different functions $a$.\n",
    "Here $\\Lambda$ is, of course, discretized, and the details of the discretization are discussed in the notebook describing the generation of the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import opnet\n",
    "from volume_inversion_data import generate_data, save_data, load_data\n",
    "\n",
    "#PATH = './volume_inversion_ReLU3.pth' #biggest data (10000/2500)\n",
    "#PATH = './volume_inversion_NOReLU3.pth' #biggest data (10000/2500)\n",
    "\n",
    "#PATH = './volume_inversion_NOReLU2.pth' #big data (6000/1000)\n",
    "#PATH = './volume_inversion_ReLU2.pth' #big data (6000/1000)\n",
    "\n",
    "#PATH = './volume_inversion_NOReLU.pth' #normal data (600/100)\n",
    "#PATH = './volume_inversion_ReLU.pth' #normal data (600/100)\n",
    "\n",
    "#PATH = './volume_inversion_netLONG.pth' # trained 1600 epochs\n",
    "\n",
    "PATH = './volume_inversion_net.pth' #that network that can be overwritten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the network model and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dim = 126 # this needs be the size of Lambda_h\n",
    "num_layers = 5\n",
    "# luodaan uusi neuroverkko\n",
    "model = opnet.OperatorNet(dim, 2*num_layers, scalar_output=True, useReLU=False)\n",
    "#model = opnet.OperatorNet(dim, num_layers, scalar_output=True, useReLU=True)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_data(*generate_data(1000), \"volume_inversion_train_data1000.npz\")\n",
    "#save_data(*generate_data(350), \"volume_inversion_test_data350.npz\")\n",
    "\n",
    "train_data_path = \"volume_inversion_train_dataBIG.npz\"\n",
    "test_data_path = \"volume_inversion_test_dataBIG.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.021636\n",
      "40 0.009329\n",
      "60 0.006151\n",
      "80 0.004480\n",
      "100 0.003563\n",
      "120 0.003026\n",
      "140 0.002676\n",
      "160 0.002423\n",
      "180 0.002223\n",
      "200 0.002057\n",
      "220 0.001916\n",
      "240 0.001792\n",
      "260 0.001684\n",
      "280 0.001588\n",
      "300 0.001502\n",
      "320 0.001425\n",
      "340 0.001356\n",
      "360 0.001294\n",
      "380 0.001238\n",
      "400 0.001187\n",
      "420 0.001141\n",
      "440 0.001100\n",
      "460 0.001062\n",
      "480 0.001027\n",
      "500 0.000995\n",
      "520 0.000966\n",
      "540 0.000939\n",
      "560 0.000914\n",
      "580 0.000891\n",
      "600 0.000869\n",
      "620 0.000849\n",
      "640 0.000830\n",
      "660 0.000812\n",
      "680 0.000796\n",
      "700 0.000780\n",
      "720 0.000765\n",
      "740 0.000751\n",
      "760 0.000738\n",
      "780 0.000725\n",
      "800 0.000713\n",
      "820 0.000702\n",
      "840 0.000691\n",
      "860 0.000680\n",
      "880 0.000670\n",
      "900 0.000661\n",
      "920 0.000651\n",
      "940 0.000642\n",
      "960 0.000634\n",
      "980 0.000625\n",
      "1000 0.000617\n",
      "1020 0.000610\n",
      "1040 0.000602\n",
      "1060 0.000595\n",
      "1080 0.000588\n",
      "1100 0.000581\n",
      "1120 0.000574\n",
      "1140 0.000568\n",
      "1160 0.000562\n",
      "1180 0.000556\n",
      "1200 0.000550\n",
      "1220 0.000544\n",
      "1240 0.000538\n",
      "1260 0.000533\n",
      "1280 0.000528\n",
      "1300 0.000522\n",
      "1320 0.000517\n",
      "1340 0.000513\n",
      "1360 0.000508\n",
      "1380 0.000503\n",
      "1400 0.000498\n",
      "1420 0.000494\n",
      "1440 0.000490\n",
      "1460 0.000485\n",
      "1480 0.000481\n",
      "1500 0.000477\n",
      "1520 0.000473\n",
      "1540 0.000469\n",
      "1560 0.000465\n",
      "1580 0.000462\n",
      "1600 0.000458\n"
     ]
    }
   ],
   "source": [
    "import wave_training_and_testing\n",
    "import os.path\n",
    "\n",
    "# update changes\n",
    "from importlib import reload \n",
    "reload(wave_training_and_testing)\n",
    "reload(opnet)\n",
    "\n",
    "lr=1e-4\n",
    "\n",
    "# upload the neural network used earlier:\n",
    "# if os.path.exists(PATH):\n",
    "#     # PATH-tiedostoon on tallennettu verkko ja t채m채 lataa sen kertoimet ylemp채n채 \n",
    "#     # luotuun verkkoon, eli jatketaan vanhalla verkolla\n",
    "#     model.load_state_dict(torch.load(PATH)) \n",
    "# else:\n",
    "#     print(\"no old PATH, I'll make a new one\")\n",
    "\n",
    "wave_training_and_testing.wave_training_and_testing(model, loss_fn, lr, PATH, train_data_path, test_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the optimization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate parameter is from the quickstart guide \n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the training data multiple times (epochs) and \n",
    "save the optimized parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(2): \n",
    "#     print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "#     for batch, (X, y) in enumerate(train_loader):\n",
    "#         # Compute prediction error\n",
    "#         pred = model(X)\n",
    "#         loss = loss_fn(pred, y)\n",
    "#         # Backpropagation\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         # Print statistics\n",
    "#         if batch % 10 == 0:\n",
    "#             n, N = (batch + 1) * len(X), len(train_loader.dataset)\n",
    "#             print(f\"loss: {loss.item():>7f}  [{n:>5d}/{N:>5d}]\")\n",
    "\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "If we have already trained the network, we can just load its parameters. (Note that we still need to run the initialization.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load trained variables\n",
    "# model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the testing data\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     load_data(\"volume_inversion_test_data.npz\"), \n",
    "#     batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a couple of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(test_loader)\n",
    "# X, y = dataiter.next()\n",
    "# with torch.no_grad():\n",
    "#     pred = model(X)\n",
    "# print(\"True: \")\n",
    "# print(y[:2])\n",
    "# print(\"Prediction: \")\n",
    "# print(pred[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_batches = len(test_loader)\n",
    "# test_loss = 0\n",
    "# with torch.no_grad():\n",
    "#     for X, y in test_loader:\n",
    "#         pred = model(X)\n",
    "#         test_loss += loss_fn(pred, y).item()\n",
    "# test_loss /= num_batches\n",
    "# print(f\"Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('oprecnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c224d568f0f8fe9cd67a2fae7eb3734fc94b3a5cce8cb776805a0b269447ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
